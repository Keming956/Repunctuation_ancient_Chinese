{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\"\"\"\n",
    "Plan A：Embedding×2 + Conv1D + 2 couches GRU\n",
    "\"\"\"\n",
    "Mais ce modèle est trop nul donc on lui a abandonné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, glob, random, re, shutil, collections, pathlib\n",
    "import numpy as np, tensorflow as tf, keras\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------- 1. chemin ----------\n",
    "DATA_DIR = pathlib.Path(\"./dataset\")\n",
    "TRAIN_DIR, DEV_DIR, TEST_DIR = DATA_DIR/\"train\", DATA_DIR/\"dev\", DATA_DIR/\"test\"\n",
    "PRED_DIR = DATA_DIR/\"pred\"; PRED_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "# if not DEV_DIR.exists() or not any(DEV_DIR.iterdir()):\n",
    "#     DEV_DIR.mkdir(exist_ok=True)\n",
    "#     files = sorted(TRAIN_DIR.glob(\"*.txt\")); random.shuffle(files)\n",
    "#     for f in files[: int(0.1*len(files))]:\n",
    "#         shutil.move(str(f), DEV_DIR/f.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------- 2.découpage de phrases  ----------\n",
    "CH_PUNCTS = \"，。、：；？！「」\"\n",
    "def strip_punct(s): return re.sub(f\"[{CH_PUNCTS}]\", \"\", s)\n",
    "\n",
    "def read(folder, with_punct=True):\n",
    "    s, t = [], []\n",
    "    for fp in sorted(folder.glob(\"*.txt\")):\n",
    "        txt = fp.read_text(encoding=\"utf-8\").strip()\n",
    "        if not txt: continue\n",
    "        s.append(strip_punct(txt) if with_punct else txt)\n",
    "        t.append(txt if with_punct else \"\")\n",
    "    return s, t\n",
    "\n",
    "train_src, train_tgt = read(TRAIN_DIR, True)\n",
    "dev_src,   dev_tgt   = read(DEV_DIR,   True)\n",
    "test_src,  _         = read(TEST_DIR,  False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------- 3. TextVectorization ----------\n",
    "tv = keras.layers.TextVectorization(\n",
    "        standardize=None, split=\"character\",\n",
    "        output_mode=\"int\", output_sequence_length=256)\n",
    "tv.adapt(train_src + train_tgt + dev_src + dev_tgt)\n",
    "VOCAB, PAD = tv.vocabulary_size(), 0\n",
    "\n",
    "\n",
    "def shift_right(tensor):               \n",
    "    pad = tf.zeros_like(tensor[:, :1]) \n",
    "    return tf.concat([pad, tensor[:, :-1]], axis=1)\n",
    "\n",
    "def vec(src_list, tgt_list):\n",
    "    x = tv(np.array(src_list))         \n",
    "    if tgt_list[0]:                    \n",
    "        y = tv(np.array(tgt_list))     \n",
    "        y = shift_right(y)            \n",
    "        m = tf.cast(y != PAD, \"float32\")\n",
    "        return x, y, m\n",
    "    else:                              # test\n",
    "        return x, None, None\n",
    "\n",
    "\n",
    "x_tr,y_tr,m_tr = vec(train_src,train_tgt)\n",
    "x_dev,y_dev,m_dev = vec(dev_src,dev_tgt)\n",
    "x_te,_,_ = vec(test_src,[\"\"]*len(test_src))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,246,720</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,752</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,752</span> │ gru_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gru_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ gru_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,251,590</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">4870</span>)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,246,720\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m196,864\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m394,752\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m394,752\u001b[0m │ gru_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ gru_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ gru_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m1,251,590\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m4870\u001b[0m)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,485,702</span> (13.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,485,702\u001b[0m (13.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,485,702</span> (13.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,485,702\u001b[0m (13.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# -------- 4. Modèle ----------\n",
    "def build_model(vocab, emb_dim=256, conv_filters=256, gru_dim=256, drop=0.3):   \n",
    "    inp = keras.Input((None,), dtype=\"int32\")\n",
    "    x   = keras.layers.Embedding(vocab, emb_dim)(inp)\n",
    "\n",
    "    x2  = keras.layers.Conv1D(conv_filters, 3, padding=\"causal\", activation=\"relu\")(x)\n",
    "    x   = keras.layers.Add()([x, x2])\n",
    "    x   = keras.layers.LayerNormalization()(x); x = keras.layers.Dropout(drop)(x)\n",
    "\n",
    "    g1  = keras.layers.GRU(gru_dim, return_sequences=True)(x)\n",
    "    g2  = keras.layers.GRU(gru_dim, return_sequences=True)(g1)\n",
    "    x   = keras.layers.Add()([g1, g2])                     # residual\n",
    "    x   = keras.layers.LayerNormalization()(x); x = keras.layers.Dropout(drop)(x)\n",
    "\n",
    "    out = keras.layers.Dense(vocab, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inp, out)\n",
    "    loss  = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(3e-4),            \n",
    "        loss=loss,\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "    return model\n",
    "\n",
    "model = build_model(VOCAB)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------- 5. sample_weight ----------\n",
    "sw_tr, sw_dev = m_tr.numpy(), m_dev.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3/3 - 5s - 2s/step - loss: 8.4519 - sparse_categorical_accuracy: 4.3403e-04 - val_loss: 8.3797 - val_sparse_categorical_accuracy: 0.0063 - learning_rate: 3.0000e-04\n",
      "Epoch 2/30\n",
      "3/3 - 4s - 1s/step - loss: 8.3186 - sparse_categorical_accuracy: 0.0032 - val_loss: 8.2236 - val_sparse_categorical_accuracy: 0.0410 - learning_rate: 2.9918e-04\n",
      "Epoch 3/30\n",
      "3/3 - 4s - 1s/step - loss: 8.1404 - sparse_categorical_accuracy: 0.0299 - val_loss: 7.9795 - val_sparse_categorical_accuracy: 0.0830 - learning_rate: 2.9591e-04\n",
      "Epoch 4/30\n",
      "3/3 - 3s - 1s/step - loss: 7.8779 - sparse_categorical_accuracy: 0.0799 - val_loss: 7.6699 - val_sparse_categorical_accuracy: 0.0884 - learning_rate: 2.8867e-04\n",
      "Epoch 5/30\n",
      "3/3 - 3s - 1s/step - loss: 7.5585 - sparse_categorical_accuracy: 0.0921 - val_loss: 7.3869 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 2.7619e-04\n",
      "Epoch 6/30\n",
      "3/3 - 3s - 1s/step - loss: 7.2700 - sparse_categorical_accuracy: 0.0922 - val_loss: 7.1698 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 2.5769e-04\n",
      "Epoch 7/30\n",
      "3/3 - 4s - 1s/step - loss: 7.0508 - sparse_categorical_accuracy: 0.0921 - val_loss: 7.0029 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 2.3308e-04\n",
      "Epoch 8/30\n",
      "3/3 - 5s - 2s/step - loss: 6.8857 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.8742 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 2.0315e-04\n",
      "Epoch 9/30\n",
      "3/3 - 4s - 1s/step - loss: 6.7561 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.7774 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 1.6954e-04\n",
      "Epoch 10/30\n",
      "3/3 - 4s - 1s/step - loss: 6.6585 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.7077 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 1.3460e-04\n",
      "Epoch 11/30\n",
      "3/3 - 4s - 1s/step - loss: 6.5944 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.6599 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 1.0095e-04\n",
      "Epoch 12/30\n",
      "3/3 - 3s - 1s/step - loss: 6.5425 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.6288 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 7.1003e-05\n",
      "Epoch 13/30\n",
      "3/3 - 4s - 1s/step - loss: 6.5156 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.6097 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 4.6472e-05\n",
      "Epoch 14/30\n",
      "3/3 - 4s - 1s/step - loss: 6.4935 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.5987 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 2.8067e-05\n",
      "Epoch 15/30\n",
      "3/3 - 4s - 1s/step - loss: 6.4853 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.5928 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 1.5500e-05\n",
      "Epoch 16/30\n",
      "3/3 - 4s - 1s/step - loss: 6.4797 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.5899 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 7.7502e-06\n",
      "Epoch 17/30\n",
      "3/3 - 4s - 1s/step - loss: 6.4765 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.5886 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 3.4701e-06\n",
      "Epoch 18/30\n",
      "3/3 - 4s - 1s/step - loss: 6.4739 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.5881 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 1.3743e-06\n",
      "Epoch 19/30\n",
      "3/3 - 4s - 1s/step - loss: 6.4776 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.5880 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 4.7481e-07\n",
      "Epoch 20/30\n",
      "3/3 - 4s - 1s/step - loss: 6.4761 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.5879 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 1.4084e-07\n",
      "Epoch 21/30\n",
      "3/3 - 4s - 1s/step - loss: 6.4706 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.5879 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 3.5211e-08\n",
      "Epoch 22/30\n",
      "3/3 - 5s - 2s/step - loss: 6.4756 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.5879 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 7.2572e-09\n",
      "Epoch 23/30\n",
      "3/3 - 4s - 1s/step - loss: 6.4755 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.5879 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 1.2006e-09\n",
      "Epoch 24/30\n",
      "3/3 - 4s - 1s/step - loss: 6.4745 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.5879 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 1.5419e-10\n",
      "Epoch 25/30\n",
      "3/3 - 4s - 1s/step - loss: 6.4753 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.5879 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 1.4724e-11\n",
      "Epoch 26/30\n",
      "3/3 - 4s - 1s/step - loss: 6.4793 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.5879 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 9.8630e-13\n",
      "Epoch 27/30\n",
      "3/3 - 4s - 1s/step - loss: 6.4741 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.5879 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 4.2635e-14\n",
      "Epoch 28/30\n",
      "3/3 - 3s - 1s/step - loss: 6.4743 - sparse_categorical_accuracy: 0.0921 - val_loss: 6.5879 - val_sparse_categorical_accuracy: 0.0889 - learning_rate: 1.0434e-15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------- 6. Train ----------\n",
    "def cosine_lr(epoch, lr0=3e-4, total=30):\n",
    "    import math\n",
    "    return lr0 * (1 + math.cos(epoch/total * math.pi)) / 2  \n",
    "\n",
    "history = model.fit(\n",
    "    x_tr, y_tr, sample_weight=sw_tr,\n",
    "    validation_data=(x_dev, y_dev, sw_dev),\n",
    "    batch_size=32, epochs=30, verbose=2,\n",
    "    callbacks=[\n",
    "        keras.callbacks.LearningRateScheduler(cosine_lr),\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                      patience=5, restore_best_weights=True)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev macro-F1: 0.0002326937239178463\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------- 7. Dev macro-F1 ----------\n",
    "def macro_f1(y_true, y_prob, mask):\n",
    "    y_pred = y_prob.argmax(-1)\n",
    "    yt, yp = [], []\n",
    "    for t,p,m in zip(y_true.numpy(), y_pred, mask.numpy().astype(bool)):\n",
    "        yt.extend(t[m]); yp.extend(p[m])\n",
    "    return f1_score(yt, yp, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(\"Dev macro-F1:\", macro_f1(y_dev, model.predict(x_dev,32,0), m_dev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # -------- 8. Inference ----------\n",
    "# chars = tv.get_vocabulary()\n",
    "# def ids2txt(ids): return \"\".join(chars[i] for i in ids if i!=PAD)\n",
    "\n",
    "# for fp, src, logits in zip(sorted(TEST_DIR.glob(\"*.txt\")), test_src,\n",
    "#                            model.predict(x_te,32,0)):\n",
    "#     txt = ids2txt(logits.argmax(-1))\n",
    "#     if not any(p in txt for p in CH_PUNCTS): txt = src   # fallback\n",
    "#     (PRED_DIR/fp.name).write_text(txt, encoding=\"utf-8\")\n",
    "\n",
    "# print(\"Saved at\", PRED_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
